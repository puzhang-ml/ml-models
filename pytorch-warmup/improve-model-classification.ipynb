{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, Pu tried to improve the model's performance on pixel error and color error. Pu did so by improving:\n",
    "1. Increase the model complexity by adding one more CNN layer.\n",
    "2. Model architecture by using batch norm.\n",
    "3. Introduce the learning rate scheduler. \n",
    "4. Add dropout layer to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train_loss: 81.254 test_loss: 42.131, pixel_error: 2.502, color_accuracy:0.315\n",
      "Epoch 501 train_loss: 2.509 test_loss: 18.435, pixel_error: 1.444, color_accuracy:0.961\n",
      "Epoch 1000 train_loss: 2.232 test_loss: 18.442, pixel_error: 1.440, color_accuracy:0.970\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from skimage.draw import disk, rectangle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setup the device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Function for generating train/test data\n",
    "def generate_data(width=32, radius_range=(3, 7), noise_range=(0, 0)):\n",
    "    img = torch.FloatTensor(3, width, width).uniform_(0, 1)\n",
    "    rad = torch.randint(low=radius_range[0], high=radius_range[1], size=(1,))\n",
    "    circle_pt = torch.FloatTensor(2).uniform_(rad.item(), width - rad.item())\n",
    "    circle_mask = disk(circle_pt.tolist(), rad.item(), shape=(width, width))\n",
    "    clr = torch.randint(3, size=(1,)).item()\n",
    "    noise_lvl = torch.FloatTensor(1).uniform_(*noise_range).item()\n",
    "    img[clr][circle_mask] = (1 - img[clr][circle_mask] * noise_lvl)\n",
    "    return img, torch.concat((rad, circle_pt)), clr\n",
    "\n",
    "# Metrics calculation\n",
    "def compute_pixel_error(pred, label):\n",
    "    return torch.mean(torch.abs(pred - label)).item()\n",
    "\n",
    "def compute_color_accuracy(pred, label):\n",
    "    return torch.mean(pred == label, dtype=torch.float)\n",
    "\n",
    "# Training loop\n",
    "def model_training(train_ldr, test_ldr, model, shape_loss_fn, clr_loss_fn, opt, sched, num_epochs=1000):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss, _, _ = one_epoch(model, opt, shape_loss_fn, clr_loss_fn, train_ldr)\n",
    "        sched.step()\n",
    "        if epoch in [0, num_epochs // 2, num_epochs - 1]:\n",
    "            model.eval()\n",
    "            test_loss, pixel_error, clr_accuracy = one_epoch(model, opt, shape_loss_fn, clr_loss_fn, test_ldr, training=False)\n",
    "            print(f'Epoch {epoch + 1} train_loss: {train_loss:.3f} test_loss: {test_loss:.3f}, pixel_error: {pixel_error:.3f}, color_accuracy:{clr_accuracy:.3f}')\n",
    "\n",
    "# Run one epoch's training\n",
    "def one_epoch(model, opt, shape_loss_fn, clr_loss_fn, ldr, training=True):\n",
    "    losses = []\n",
    "    pixel_errors = []\n",
    "    clr_accuracies = []\n",
    "    for _, data_batch in enumerate(ldr):\n",
    "        imgs, lbl_shape, lbl_clr = [x.to(device) for x in data_batch]\n",
    "        pred_shape, pred_clr = model(imgs)\n",
    "        loss = (3 * shape_loss_fn(pred_shape, lbl_shape) + clr_loss_fn(pred_clr, lbl_clr))\n",
    "        if training:\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        losses.append(loss.item())\n",
    "        pixel_errors.append(compute_pixel_error(pred_shape, lbl_shape))\n",
    "        clr_accuracies.append(compute_color_accuracy(torch.argmax(pred_clr, dim=1), lbl_clr))\n",
    "    return torch.Tensor(losses).mean(), torch.Tensor(pixel_errors).mean(), torch.Tensor(clr_accuracies).mean()\n",
    "\n",
    "\n",
    "# Generate the data and load into Dataset & DataLoader\n",
    "train_data = [generate_data(noise_range=[0.33, 0.66]) for _ in range(10000)]\n",
    "test_data = [generate_data(noise_range=[0.33, 0.66]) for _ in range(1000)]\n",
    "train_ldr = torch.utils.data.DataLoader(train_data, batch_size=100)\n",
    "test_ldr = torch.utils.data.DataLoader(test_data, batch_size=100)\n",
    "\n",
    "# Loss functions\n",
    "shape_loss_fn = nn.MSELoss(reduction='mean')\n",
    "color_loss_fn = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "# Model definition\n",
    "class ANNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANNModel, self).__init__()\n",
    "\n",
    "        # for any CNN, the output size is (W - F + 2P) / S + 1, W is width, F is kernel size, P is padding, S is stride\n",
    "        self.feature_layers = nn.Sequential(                                # 100x3x32x32\n",
    "            nn.Conv2d(3, 128, kernel_size=3, stride=2, padding=1),          # 100x128x16x16\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),        # 100x256x8x8\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),        # 100x512x4x4\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "        )\n",
    "        self.embed_size = 4 * 4 * 512\n",
    "        self.shape_out = nn.Linear(self.embed_size, 3)                      # 100x3 \n",
    "        self.color_out = nn.Linear(self.embed_size, 3)                      # 100x3\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_layers(x)\n",
    "        x = x.view(-1, self.embed_size)\n",
    "        shape_res = self.shape_out(x)\n",
    "        color_res = torch.sigmoid(self.color_out(x))\n",
    "        return shape_res, color_res\n",
    "\n",
    "model = ANNModel()\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f'Will use {torch.cuda.device_count()} GPUs!')\n",
    "    model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer and scheduler setup\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "# The learning rate will drop 50% every 100 steps/epochs\n",
    "sched = lr_scheduler.StepLR(opt, step_size=100, gamma=0.7)\n",
    "\n",
    "# Start training\n",
    "model_training(train_ldr, test_ldr, model, shape_loss_fn, color_loss_fn, opt, sched, num_epochs=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
